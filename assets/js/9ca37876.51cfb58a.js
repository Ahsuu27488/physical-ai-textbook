"use strict";(globalThis.webpackChunkmy_website_1=globalThis.webpackChunkmy_website_1||[]).push([[958],{6563:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>t,default:()=>m,frontMatter:()=>r,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"module-2/lesson-3-ros-gazebo-integration","title":"Lesson 3 - ROS-Gazebo Integration","description":"Learning Objectives","source":"@site/docs/module-2/lesson-3-ros-gazebo-integration.md","sourceDirName":"module-2","slug":"/module-2/lesson-3-ros-gazebo-integration","permalink":"/physical-ai-textbook/docs/module-2/lesson-3-ros-gazebo-integration","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-2/lesson-3-ros-gazebo-integration.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"title":"Lesson 3 - ROS-Gazebo Integration","sidebar_position":6},"sidebar":"textbookSidebar","previous":{"title":"Lesson 2 - Sensor Simulation in Gazebo","permalink":"/physical-ai-textbook/docs/module-2/lesson-2-sensor-simulation"},"next":{"title":"Module 3 - The AI-Robot Brain (NVIDIA Isaac\u2122)","permalink":"/physical-ai-textbook/docs/module-3/intro"}}');var i=s(4848),o=s(8453);const r={title:"Lesson 3 - ROS-Gazebo Integration",sidebar_position:6},t="Lesson 3: ROS-Gazebo Integration",l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction to ROS-Gazebo Integration",id:"introduction-to-ros-gazebo-integration",level:2},{value:"Key Components of ROS-Gazebo Integration",id:"key-components-of-ros-gazebo-integration",level:3},{value:"Installing Gazebo ROS Packages",id:"installing-gazebo-ros-packages",level:2},{value:"Prerequisites",id:"prerequisites",level:3},{value:"Basic ROS-Gazebo Launch File",id:"basic-ros-gazebo-launch-file",level:2},{value:"Simple Robot Launch File",id:"simple-robot-launch-file",level:3},{value:"Gazebo Plugins for ROS Integration",id:"gazebo-plugins-for-ros-integration",level:2},{value:"Differential Drive Plugin",id:"differential-drive-plugin",level:3},{value:"Camera Plugin",id:"camera-plugin",level:3},{value:"IMU Plugin",id:"imu-plugin",level:3},{value:"Controlling Robots in Simulation",id:"controlling-robots-in-simulation",level:2},{value:"Robot Control Node",id:"robot-control-node",level:3},{value:"Launch File with Complete Robot Simulation",id:"launch-file-with-complete-robot-simulation",level:2},{value:"Advanced Launch File",id:"advanced-launch-file",level:3},{value:"Processing Sensor Data from Simulation",id:"processing-sensor-data-from-simulation",level:2},{value:"Sensor Data Processing Node",id:"sensor-data-processing-node",level:3},{value:"Advanced Simulation Features",id:"advanced-simulation-features",level:2},{value:"Creating Custom Worlds",id:"creating-custom-worlds",level:3},{value:"Dynamic Obstacles",id:"dynamic-obstacles",level:3},{value:"Practical Exercise: Complete Simulation Setup",id:"practical-exercise-complete-simulation-setup",level:2},{value:"Steps:",id:"steps",level:3},{value:"Troubleshooting Common Issues",id:"troubleshooting-common-issues",level:2},{value:"1. Robot Not Spawning",id:"1-robot-not-spawning",level:3},{value:"2. Sensor Data Not Publishing",id:"2-sensor-data-not-publishing",level:3},{value:"3. Robot Control Issues",id:"3-robot-control-issues",level:3},{value:"4. TF Issues",id:"4-tf-issues",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Simulation Speed",id:"simulation-speed",level:3},{value:"Sensor Processing",id:"sensor-processing",level:3},{value:"Summary",id:"summary",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"lesson-3-ros-gazebo-integration",children:"Lesson 3: ROS-Gazebo Integration"})}),"\n",(0,i.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,i.jsx)(n.p,{children:"By the end of this lesson, students will be able to:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Integrate ROS 2 with Gazebo simulation"}),"\n",(0,i.jsx)(n.li,{children:"Control simulated robots using ROS 2 nodes"}),"\n",(0,i.jsx)(n.li,{children:"Process sensor data from Gazebo in ROS 2"}),"\n",(0,i.jsx)(n.li,{children:"Create launch files for complete simulation environments"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"introduction-to-ros-gazebo-integration",children:"Introduction to ROS-Gazebo Integration"}),"\n",(0,i.jsx)(n.p,{children:"The integration between ROS and Gazebo enables seamless development and testing of robotic systems. Gazebo provides realistic physics simulation and sensor modeling, while ROS provides the communication framework and tooling for robot development."}),"\n",(0,i.jsx)(n.h3,{id:"key-components-of-ros-gazebo-integration",children:"Key Components of ROS-Gazebo Integration"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Gazebo ROS Packages"}),": Bridge between Gazebo and ROS"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Robot Description"}),": URDF models loaded into Gazebo"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Sensor Plugins"}),": Publish sensor data to ROS topics"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Controller Plugins"}),": Subscribe to ROS topics for actuator control"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"TF Publishers"}),": Maintain coordinate frame relationships"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"installing-gazebo-ros-packages",children:"Installing Gazebo ROS Packages"}),"\n",(0,i.jsx)(n.h3,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Install ROS 2 Gazebo packages\nsudo apt update\nsudo apt install ros-humble-gazebo-ros-pkgs\nsudo apt install ros-humble-gazebo-ros2-control\nsudo apt install ros-humble-gazebo-ros2-control-demos\n"})}),"\n",(0,i.jsx)(n.h2,{id:"basic-ros-gazebo-launch-file",children:"Basic ROS-Gazebo Launch File"}),"\n",(0,i.jsx)(n.h3,{id:"simple-robot-launch-file",children:"Simple Robot Launch File"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:'<launch>\n  \x3c!-- Arguments --\x3e\n  <arg name="world" default="empty"/>\n  <arg name="paused" default="false"/>\n  <arg name="use_sim_time" default="true"/>\n  <arg name="gui" default="true"/>\n  <arg name="headless" default="false"/>\n  <arg name="debug" default="false"/>\n\n  \x3c!-- Gazebo server --\x3e\n  <include file="$(find gazebo_ros)/launch/empty_world.launch.py">\n    <arg name="world_name" value="$(var world)"/>\n    <arg name="paused" value="$(var paused)"/>\n    <arg name="use_sim_time" value="$(var use_sim_time)"/>\n    <arg name="gui" value="$(var gui)"/>\n    <arg name="headless" value="$(var headless)"/>\n    <arg name="debug" value="$(var debug)"/>\n  </include>\n\n  \x3c!-- Load robot description parameter --\x3e\n  <param name="robot_description"\n         command="xacro $(find my_robot_description)/urdf/my_robot.xacro"/>\n\n  \x3c!-- Spawn robot in Gazebo --\x3e\n  <node name="spawn_urdf" pkg="gazebo_ros" type="spawn_entity.py"\n        args="-topic robot_description -entity my_robot"/>\n\n  \x3c!-- Robot state publisher --\x3e\n  <node name="robot_state_publisher" pkg="robot_state_publisher"\n        type="robot_state_publisher" respawn="false" output="screen"/>\n</launch>\n'})}),"\n",(0,i.jsx)(n.h2,{id:"gazebo-plugins-for-ros-integration",children:"Gazebo Plugins for ROS Integration"}),"\n",(0,i.jsx)(n.h3,{id:"differential-drive-plugin",children:"Differential Drive Plugin"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:'\x3c!-- In your URDF/Xacro file --\x3e\n<gazebo>\n  <plugin name="diff_drive" filename="libgazebo_ros_diff_drive.so">\n    \x3c!-- Wheel information --\x3e\n    <left_joint>left_wheel_joint</left_joint>\n    <right_joint>right_wheel_joint</right_joint>\n    <wheel_separation>0.3</wheel_separation>\n    <wheel_diameter>0.15</wheel_diameter>\n\n    \x3c!-- Limits --\x3e\n    <max_wheel_torque>20</max_wheel_torque>\n    <max_wheel_acceleration>1.0</max_wheel_acceleration>\n\n    \x3c!-- Topics --\x3e\n    <command_topic>cmd_vel</command_topic>\n    <odometry_topic>odom</odometry_topic>\n    <odometry_frame>odom</odometry_frame>\n    <robot_base_frame>base_link</robot_base_frame>\n\n    \x3c!-- Rate --\x3e\n    <publish_rate>50</publish_rate>\n    <odometry_publish_rate>50</odometry_publish_rate>\n  </plugin>\n</gazebo>\n'})}),"\n",(0,i.jsx)(n.h3,{id:"camera-plugin",children:"Camera Plugin"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:'<gazebo reference="camera_link">\n  <sensor name="camera" type="camera">\n    <always_on>true</always_on>\n    <update_rate>30</update_rate>\n    <camera name="head">\n      <horizontal_fov>1.047</horizontal_fov>\n      <image>\n        <width>640</width>\n        <height>480</height>\n        <format>R8G8B8</format>\n      </image>\n      <clip>\n        <near>0.1</near>\n        <far>100</far>\n      </clip>\n      <noise>\n        <type>gaussian</type>\n        <mean>0.0</mean>\n        <stddev>0.007</stddev>\n      </noise>\n    </camera>\n    <plugin name="camera_controller" filename="libgazebo_ros_camera.so">\n      <frame_name>camera_link</frame_name>\n      <topic_name>camera/image_raw</topic_name>\n      <camera_info_topic_name>camera/camera_info</camera_info_topic_name>\n    </plugin>\n  </sensor>\n</gazebo>\n'})}),"\n",(0,i.jsx)(n.h3,{id:"imu-plugin",children:"IMU Plugin"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:'<gazebo reference="imu_link">\n  <sensor name="imu_sensor" type="imu">\n    <always_on>true</always_on>\n    <update_rate>100</update_rate>\n    <imu>\n      <angular_velocity>\n        <x>\n          <noise type="gaussian">\n            <mean>0.0</mean>\n            <stddev>2e-4</stddev>\n            <bias_mean>0.0000075</bias_mean>\n            <bias_stddev>0.0000008</bias_stddev>\n          </noise>\n        </x>\n        <y>\n          <noise type="gaussian">\n            <mean>0.0</mean>\n            <stddev>2e-4</stddev>\n            <bias_mean>0.0000075</bias_mean>\n            <bias_stddev>0.0000008</bias_stddev>\n          </noise>\n        </y>\n        <z>\n          <noise type="gaussian">\n            <mean>0.0</mean>\n            <stddev>2e-4</stddev>\n            <bias_mean>0.0000075</bias_mean>\n            <bias_stddev>0.0000008</bias_stddev>\n          </noise>\n        </z>\n      </angular_velocity>\n      <linear_acceleration>\n        <x>\n          <noise type="gaussian">\n            <mean>0.0</mean>\n            <stddev>1.7e-2</stddev>\n            <bias_mean>0.1</bias_mean>\n            <bias_stddev>0.001</bias_stddev>\n          </noise>\n        </x>\n        <y>\n          <noise type="gaussian">\n            <mean>0.0</mean>\n            <stddev>1.7e-2</stddev>\n            <bias_mean>0.1</bias_mean>\n            <bias_stddev>0.001</bias_stddev>\n          </noise>\n        </y>\n        <z>\n          <noise type="gaussian">\n            <mean>0.0</mean>\n            <stddev>1.7e-2</stddev>\n            <bias_mean>0.1</bias_mean>\n            <bias_stddev>0.001</bias_stddev>\n          </noise>\n        </z>\n      </linear_acceleration>\n    </imu>\n    <plugin name="imu_plugin" filename="libgazebo_ros_imu.so">\n      <frame_name>imu_link</frame_name>\n      <topic_name>imu/data</topic_name>\n    </plugin>\n  </sensor>\n</gazebo>\n'})}),"\n",(0,i.jsx)(n.h2,{id:"controlling-robots-in-simulation",children:"Controlling Robots in Simulation"}),"\n",(0,i.jsx)(n.h3,{id:"robot-control-node",children:"Robot Control Node"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import Twist\nfrom sensor_msgs.msg import LaserScan, Image\nfrom nav_msgs.msg import Odometry\nimport cv2\nfrom cv_bridge import CvBridge\nimport numpy as np\n\nclass RobotController(Node):\n    def __init__(self):\n        super().__init__(\'robot_controller\')\n\n        # Create publishers\n        self.cmd_vel_pub = self.create_publisher(Twist, \'cmd_vel\', 10)\n\n        # Create subscribers\n        self.odom_sub = self.create_subscription(\n            Odometry, \'odom\', self.odom_callback, 10)\n        self.scan_sub = self.create_subscription(\n            LaserScan, \'scan\', self.scan_callback, 10)\n        self.image_sub = self.create_subscription(\n            Image, \'camera/image_raw\', self.image_callback, 10)\n\n        # Create timer for control loop\n        self.timer = self.create_timer(0.1, self.control_loop)\n\n        # Initialize variables\n        self.current_pose = None\n        self.laser_data = None\n        self.bridge = CvBridge()\n        self.get_logger().info(\'Robot controller initialized\')\n\n    def odom_callback(self, msg):\n        """Handle odometry messages"""\n        self.current_pose = msg.pose.pose\n\n    def scan_callback(self, msg):\n        """Handle laser scan messages"""\n        self.laser_data = msg.ranges\n\n    def image_callback(self, msg):\n        """Handle image messages"""\n        try:\n            cv_image = self.bridge.imgmsg_to_cv2(msg, "bgr8")\n            # Process image here\n            self.process_image(cv_image)\n        except Exception as e:\n            self.get_logger().error(f\'Error processing image: {e}\')\n\n    def process_image(self, image):\n        """Process the received image"""\n        # Example: Detect red objects\n        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n        lower_red = np.array([0, 50, 50])\n        upper_red = np.array([10, 255, 255])\n        mask = cv2.inRange(hsv, lower_red, upper_red)\n\n        # Find contours\n        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n        if contours:\n            # Find largest contour\n            largest_contour = max(contours, key=cv2.contourArea)\n            if cv2.contourArea(largest_contour) > 100:  # Minimum area threshold\n                # Calculate center of contour\n                M = cv2.moments(largest_contour)\n                if M["m00"] != 0:\n                    cx = int(M["m10"] / M["m00"])\n                    image_width = image.shape[1]\n                    center_x = cx - image_width // 2  # Center relative to image center\n\n                    # Generate control command based on object position\n                    cmd_vel = Twist()\n                    cmd_vel.angular.z = -0.002 * center_x  # Turn toward object\n                    cmd_vel.linear.x = 0.2  # Move forward slowly\n                    self.cmd_vel_pub.publish(cmd_vel)\n\n    def control_loop(self):\n        """Main control loop"""\n        if self.laser_data is not None:\n            # Simple obstacle avoidance\n            min_distance = min(self.laser_data) if self.laser_data else float(\'inf\')\n\n            cmd_vel = Twist()\n            if min_distance < 0.5:  # Obstacle detected within 0.5m\n                cmd_vel.linear.x = 0.0\n                cmd_vel.angular.z = 0.5  # Turn away from obstacle\n            else:\n                cmd_vel.linear.x = 0.2  # Move forward\n                cmd_vel.angular.z = 0.0\n\n            self.cmd_vel_pub.publish(cmd_vel)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    controller = RobotController()\n\n    try:\n        rclpy.spin(controller)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        controller.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,i.jsx)(n.h2,{id:"launch-file-with-complete-robot-simulation",children:"Launch File with Complete Robot Simulation"}),"\n",(0,i.jsx)(n.h3,{id:"advanced-launch-file",children:"Advanced Launch File"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:'<launch>\n  \x3c!-- Arguments --\x3e\n  <arg name="world" default="worlds/empty.world"/>\n  <arg name="paused" default="false"/>\n  <arg name="use_sim_time" default="true"/>\n  <arg name="gui" default="true"/>\n  <arg name="headless" default="false"/>\n  <arg name="debug" default="false"/>\n\n  \x3c!-- Gazebo --\x3e\n  <include file="$(find gazebo_ros)/launch/empty_world.launch.py">\n    <arg name="world_name" value="$(var world)"/>\n    <arg name="paused" value="$(var paused)"/>\n    <arg name="use_sim_time" value="$(var use_sim_time)"/>\n    <arg name="gui" value="$(var gui)"/>\n    <arg name="headless" value="$(var headless)"/>\n    <arg name="debug" value="$(var debug)"/>\n  </include>\n\n  \x3c!-- Robot Description --\x3e\n  <param name="robot_description"\n         command="xacro $(find my_robot_description)/urdf/my_robot.xacro"/>\n\n  \x3c!-- Spawn Robot --\x3e\n  <node name="spawn_urdf" pkg="gazebo_ros" type="spawn_entity.py"\n        args="-topic robot_description -entity my_robot"\n        output="screen"/>\n\n  \x3c!-- Robot State Publisher --\x3e\n  <node name="robot_state_publisher" pkg="robot_state_publisher"\n        type="robot_state_publisher" respawn="false" output="screen">\n    <param name="use_sim_time" value="$(var use_sim_time)"/>\n  </node>\n\n  \x3c!-- Joint State Publisher (for non-actuated joints) --\x3e\n  <node name="joint_state_publisher" pkg="joint_state_publisher"\n        type="joint_state_publisher" respawn="false" output="screen">\n    <param name="use_sim_time" value="$(var use_sim_time)"/>\n  </node>\n\n  \x3c!-- Robot Controller --\x3e\n  <node name="robot_controller" pkg="my_robot_controller"\n        type="robot_controller.py" respawn="false" output="screen">\n    <param name="use_sim_time" value="$(var use_sim_time)"/>\n  </node>\n\n  \x3c!-- RViz --\x3e\n  <node name="rviz" pkg="rviz2" type="rviz2"\n        args="-d $(find my_robot_description)/config/robot.rviz"\n        respawn="false"/>\n</launch>\n'})}),"\n",(0,i.jsx)(n.h2,{id:"processing-sensor-data-from-simulation",children:"Processing Sensor Data from Simulation"}),"\n",(0,i.jsx)(n.h3,{id:"sensor-data-processing-node",children:"Sensor Data Processing Node"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import LaserScan, Image, Imu\nfrom geometry_msgs.msg import Twist\nfrom std_msgs.msg import Float32\nimport numpy as np\nfrom cv_bridge import CvBridge\nimport cv2\n\nclass SensorProcessor(Node):\n    def __init__(self):\n        super().__init__('sensor_processor')\n\n        # Create subscribers\n        self.scan_sub = self.create_subscription(\n            LaserScan, 'scan', self.scan_callback, 10)\n        self.image_sub = self.create_subscription(\n            Image, 'camera/image_raw', self.image_callback, 10)\n        self.imu_sub = self.create_subscription(\n            Imu, 'imu/data', self.imu_callback, 10)\n\n        # Create publishers\n        self.obstacle_distance_pub = self.create_publisher(\n            Float32, 'obstacle_distance', 10)\n        self.velocity_cmd_pub = self.create_publisher(\n            Twist, 'cmd_vel', 10)\n\n        # Initialize\n        self.bridge = CvBridge()\n        self.latest_scan = None\n        self.latest_imu = None\n        self.get_logger().info('Sensor processor initialized')\n\n    def scan_callback(self, msg):\n        \"\"\"Process laser scan data\"\"\"\n        self.latest_scan = msg\n\n        # Calculate minimum distance in front of robot (forward 30 degrees)\n        ranges = np.array(msg.ranges)\n        # Filter out invalid ranges\n        valid_ranges = ranges[np.isfinite(ranges)]\n\n        if len(valid_ranges) > 0:\n            min_distance = Float32()\n            min_distance.data = float(np.min(valid_ranges))\n            self.obstacle_distance_pub.publish(min_distance)\n\n    def image_callback(self, msg):\n        \"\"\"Process camera image\"\"\"\n        try:\n            cv_image = self.bridge.imgmsg_to_cv2(msg, \"bgr8\")\n\n            # Example: Detect lines using Hough transform\n            gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)\n            edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n            lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=100,\n                                   minLineLength=50, maxLineGap=10)\n\n            if lines is not None:\n                # Draw detected lines\n                for line in lines:\n                    x1, y1, x2, y2 = line[0]\n                    cv2.line(cv_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n\n                # Show processed image\n                cv2.imshow('Processed Image', cv_image)\n                cv2.waitKey(1)\n\n        except Exception as e:\n            self.get_logger().error(f'Error processing image: {e}')\n\n    def imu_callback(self, msg):\n        \"\"\"Process IMU data\"\"\"\n        self.latest_imu = msg\n\n        # Example: Calculate orientation from quaternion\n        import math\n        w, x, y, z = msg.orientation.w, msg.orientation.x, msg.orientation.y, msg.orientation.z\n        # Convert quaternion to Euler angles (simplified)\n        yaw = math.atan2(2*(w*z + x*y), 1 - 2*(y*y + z*z))\n\n        # Use IMU data for navigation\n        self.adjust_navigation(yaw)\n\n    def adjust_navigation(self, current_yaw):\n        \"\"\"Adjust navigation based on IMU data\"\"\"\n        if self.latest_scan is not None:\n            # Simple wall following algorithm\n            scan = self.latest_scan\n            # Get ranges for left, front, right\n            mid_idx = len(scan.ranges) // 2\n            front_range = scan.ranges[mid_idx] if np.isfinite(scan.ranges[mid_idx]) else float('inf')\n            left_range = scan.ranges[len(scan.ranges)//4] if np.isfinite(scan.ranges[len(scan.ranges)//4]) else float('inf')\n            right_range = scan.ranges[3*len(scan.ranges)//4] if np.isfinite(scan.ranges[3*len(scan.ranges)//4]) else float('inf')\n\n            cmd_vel = Twist()\n            if front_range < 0.5:  # Too close to front obstacle\n                cmd_vel.angular.z = 0.5  # Turn right\n            elif right_range < 0.3:  # Too close to right wall\n                cmd_vel.angular.z = 0.3  # Turn left slightly\n            elif left_range < 0.3:  # Too close to left wall\n                cmd_vel.angular.z = -0.3  # Turn right slightly\n            else:\n                cmd_vel.linear.x = 0.2  # Move forward\n\n            self.velocity_cmd_pub.publish(cmd_vel)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    processor = SensorProcessor()\n\n    try:\n        rclpy.spin(processor)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        cv2.destroyAllWindows()\n        processor.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,i.jsx)(n.h2,{id:"advanced-simulation-features",children:"Advanced Simulation Features"}),"\n",(0,i.jsx)(n.h3,{id:"creating-custom-worlds",children:"Creating Custom Worlds"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:'\x3c!-- custom_world.world --\x3e\n<?xml version="1.0" ?>\n<sdf version="1.7">\n  <world name="custom_world">\n    \x3c!-- Physics --\x3e\n    <physics type="ode">\n      <gravity>0 0 -9.8</gravity>\n      <max_step_size>0.001</max_step_size>\n      <real_time_factor>1</real_time_factor>\n    </physics>\n\n    \x3c!-- Ground plane --\x3e\n    <include>\n      <uri>model://ground_plane</uri>\n    </include>\n\n    \x3c!-- Sun --\x3e\n    <include>\n      <uri>model://sun</uri>\n    </include>\n\n    \x3c!-- Custom objects --\x3e\n    <model name="table">\n      <pose>2 0 0 0 0 0</pose>\n      <static>true</static>\n      <link name="link">\n        <collision name="collision">\n          <geometry>\n            <box>\n              <size>1 0.8 0.8</size>\n            </box>\n          </geometry>\n        </collision>\n        <visual name="visual">\n          <geometry>\n            <box>\n              <size>1 0.8 0.8</size>\n            </box>\n          </geometry>\n          <material>\n            <ambient>0.8 0.6 0.4 1</ambient>\n            <diffuse>0.8 0.6 0.4 1</diffuse>\n          </material>\n        </visual>\n      </link>\n    </model>\n\n    \x3c!-- Add more objects as needed --\x3e\n  </world>\n</sdf>\n'})}),"\n",(0,i.jsx)(n.h3,{id:"dynamic-obstacles",children:"Dynamic Obstacles"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:'\x3c!-- Dynamic obstacle that moves in a circle --\x3e\n<model name="moving_obstacle">\n  <link name="link">\n    <visual name="visual">\n      <geometry>\n        <sphere>\n          <radius>0.1</radius>\n        </sphere>\n      </geometry>\n      <material>\n        <ambient>1 0 0 1</ambient>\n        <diffuse>1 0 0 1</diffuse>\n      </material>\n    </visual>\n    <collision name="collision">\n      <geometry>\n        <sphere>\n          <radius>0.1</radius>\n        </sphere>\n      </geometry>\n    </collision>\n    <inertial>\n      <mass>0.1</mass>\n      <inertia ixx="0.001" ixy="0" ixz="0" iyy="0.001" iyz="0" izz="0.001"/>\n    </inertial>\n  </link>\n\n  \x3c!-- Model plugin for movement --\x3e\n  <plugin name="model_move" filename="libgazebo_ros_p3d.so">\n    <alwaysOn>true</alwaysOn>\n    <updateRate>30</updateRate>\n    <bodyName>link</bodyName>\n    <topicName>model_pose</topicName>\n    <gaussianNoise>0.0</gaussianNoise>\n    <frameName>world</frameName>\n  </plugin>\n</model>\n'})}),"\n",(0,i.jsx)(n.h2,{id:"practical-exercise-complete-simulation-setup",children:"Practical Exercise: Complete Simulation Setup"}),"\n",(0,i.jsx)(n.p,{children:"Create a complete simulation environment with:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Custom Robot Model"}),": Differential drive robot with camera and IMU"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Custom World"}),": Room with obstacles"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Control Node"}),": Navigation and obstacle avoidance"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Launch File"}),": Complete simulation setup"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"steps",children:"Steps:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Create robot URDF"})," with differential drive, camera, and IMU"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Create custom world file"})," with obstacles"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Implement control node"})," that processes sensor data and controls the robot"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Create launch file"})," that starts Gazebo, spawns robot, and starts control nodes"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Test the simulation"})," and verify sensor data processing"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"troubleshooting-common-issues",children:"Troubleshooting Common Issues"}),"\n",(0,i.jsx)(n.h3,{id:"1-robot-not-spawning",children:"1. Robot Not Spawning"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Check"}),": URDF syntax and joint definitions"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Solution"}),": Validate URDF with ",(0,i.jsx)(n.code,{children:"check_urdf"})," command"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"2-sensor-data-not-publishing",children:"2. Sensor Data Not Publishing"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Check"}),": Plugin configuration and topic names"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Solution"}),": Verify plugin parameters match ROS topic expectations"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"3-robot-control-issues",children:"3. Robot Control Issues"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Check"}),": Joint names match between URDF and controller"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Solution"}),": Verify transmission elements in URDF"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"4-tf-issues",children:"4. TF Issues"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Check"}),": Robot state publisher is running"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Solution"}),": Ensure ",(0,i.jsx)(n.code,{children:"use_sim_time"})," parameter is set correctly"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,i.jsx)(n.h3,{id:"simulation-speed",children:"Simulation Speed"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Reduce physics update rate for complex scenes"}),"\n",(0,i.jsx)(n.li,{children:"Simplify collision geometries"}),"\n",(0,i.jsx)(n.li,{children:"Use fewer but larger time steps"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"sensor-processing",children:"Sensor Processing"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Reduce sensor update rates if not needed"}),"\n",(0,i.jsx)(n.li,{children:"Use smaller image resolutions for processing"}),"\n",(0,i.jsx)(n.li,{children:"Implement data throttling for high-frequency sensors"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,i.jsx)(n.p,{children:"This lesson covered the integration between ROS and Gazebo, including plugin configuration, sensor data processing, and robot control. Proper ROS-Gazebo integration is essential for developing and testing robotic systems in simulation before deployment on real hardware."}),"\n",(0,i.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,i.jsx)(n.p,{children:"In the next lesson, we'll explore advanced simulation techniques including physics parameter tuning, sensor noise modeling, and realistic environment creation."})]})}function m(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>r,x:()=>t});var a=s(6540);const i={},o=a.createContext(i);function r(e){const n=a.useContext(o);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),a.createElement(o.Provider,{value:n},e.children)}}}]);