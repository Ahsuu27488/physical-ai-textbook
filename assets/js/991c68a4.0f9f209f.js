"use strict";(globalThis.webpackChunkmy_website_1=globalThis.webpackChunkmy_website_1||[]).push([[4792],{7652:(n,e,a)=>{a.r(e),a.d(e,{assets:()=>l,contentTitle:()=>t,default:()=>m,frontMatter:()=>r,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"module-2/lesson-2-sensor-simulation","title":"Lesson 2 - Sensor Simulation in Gazebo","description":"Learning Objectives","source":"@site/docs/module-2/lesson-2-sensor-simulation.md","sourceDirName":"module-2","slug":"/module-2/lesson-2-sensor-simulation","permalink":"/physical-ai-textbook/docs/module-2/lesson-2-sensor-simulation","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-2/lesson-2-sensor-simulation.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"title":"Lesson 2 - Sensor Simulation in Gazebo","sidebar_position":5},"sidebar":"textbookSidebar","previous":{"title":"Lesson 1 - Gazebo Basics and World Building","permalink":"/physical-ai-textbook/docs/module-2/lesson-1-gazebo-basics"},"next":{"title":"Lesson 3 - ROS-Gazebo Integration","permalink":"/physical-ai-textbook/docs/module-2/lesson-3-ros-gazebo-integration"}}');var s=a(4848),o=a(8453);const r={title:"Lesson 2 - Sensor Simulation in Gazebo",sidebar_position:5},t="Lesson 2: Sensor Simulation in Gazebo",l={},d=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction to Sensor Simulation",id:"introduction-to-sensor-simulation",level:2},{value:"Camera Simulation",id:"camera-simulation",level:2},{value:"Camera SDF Configuration",id:"camera-sdf-configuration",level:3},{value:"Camera Parameters Explained",id:"camera-parameters-explained",level:3},{value:"LiDAR Simulation",id:"lidar-simulation",level:2},{value:"2D LiDAR Configuration",id:"2d-lidar-configuration",level:3},{value:"3D LiDAR Configuration (HDL-32E Example)",id:"3d-lidar-configuration-hdl-32e-example",level:3},{value:"IMU Simulation",id:"imu-simulation",level:2},{value:"IMU SDF Configuration",id:"imu-sdf-configuration",level:3},{value:"GPS Simulation",id:"gps-simulation",level:2},{value:"GPS SDF Configuration",id:"gps-sdf-configuration",level:3},{value:"Force/Torque Sensor Simulation",id:"forcetorque-sensor-simulation",level:2},{value:"Force/Torque SDF Configuration",id:"forcetorque-sdf-configuration",level:3},{value:"Complete Robot Model with Sensors",id:"complete-robot-model-with-sensors",level:2},{value:"Practical Exercise: Sensor Integration",id:"practical-exercise-sensor-integration",level:2},{value:"Sensor Noise and Realism",id:"sensor-noise-and-realism",level:2},{value:"Troubleshooting Sensor Issues",id:"troubleshooting-sensor-issues",level:2},{value:"Sensor Data Not Publishing",id:"sensor-data-not-publishing",level:3},{value:"Performance Issues",id:"performance-issues",level:3},{value:"Inaccurate Data",id:"inaccurate-data",level:3},{value:"Summary",id:"summary",level:2},{value:"Next Steps",id:"next-steps",level:2}];function c(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"lesson-2-sensor-simulation-in-gazebo",children:"Lesson 2: Sensor Simulation in Gazebo"})}),"\n",(0,s.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,s.jsx)(e.p,{children:"By the end of this lesson, students will be able to:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Configure and simulate various sensor types in Gazebo"}),"\n",(0,s.jsx)(e.li,{children:"Understand the physics behind sensor simulation"}),"\n",(0,s.jsx)(e.li,{children:"Integrate simulated sensors with ROS 2"}),"\n",(0,s.jsx)(e.li,{children:"Validate sensor data accuracy and noise characteristics"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"introduction-to-sensor-simulation",children:"Introduction to Sensor Simulation"}),"\n",(0,s.jsx)(e.p,{children:"Sensor simulation is a critical aspect of robotics development, allowing you to test perception algorithms without physical hardware. Gazebo provides realistic simulation of various sensor types, including cameras, LiDAR, IMUs, GPS, and force/torque sensors."}),"\n",(0,s.jsx)(e.h2,{id:"camera-simulation",children:"Camera Simulation"}),"\n",(0,s.jsx)(e.p,{children:"Cameras are fundamental sensors for visual perception in robotics. Gazebo provides realistic camera simulation with configurable parameters."}),"\n",(0,s.jsx)(e.h3,{id:"camera-sdf-configuration",children:"Camera SDF Configuration"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-xml",children:'<sensor name="camera" type="camera">\n  <always_on>true</always_on>\n  <update_rate>30</update_rate>\n  <camera name="head">\n    <horizontal_fov>1.047</horizontal_fov> \x3c!-- 60 degrees --\x3e\n    <image>\n      <width>640</width>\n      <height>480</height>\n      <format>R8G8B8</format>\n    </image>\n    <clip>\n      <near>0.1</near>\n      <far>100</far>\n    </clip>\n    <noise>\n      <type>gaussian</type>\n      <mean>0.0</mean>\n      <stddev>0.007</stddev>\n    </noise>\n  </camera>\n  <plugin name="camera_controller" filename="libgazebo_ros_camera.so">\n    <frame_name>camera_frame</frame_name>\n    <topic_name>camera/image_raw</topic_name>\n  </plugin>\n</sensor>\n'})}),"\n",(0,s.jsx)(e.h3,{id:"camera-parameters-explained",children:"Camera Parameters Explained"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:(0,s.jsx)(e.code,{children:"horizontal_fov"})}),": Horizontal field of view in radians"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:(0,s.jsx)(e.code,{children:"image"})}),": Resolution and format settings"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:(0,s.jsx)(e.code,{children:"clip"})}),": Near and far clipping planes"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:(0,s.jsx)(e.code,{children:"noise"})}),": Simulated sensor noise characteristics"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:(0,s.jsx)(e.code,{children:"plugin"})}),": ROS 2 interface for the sensor"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"lidar-simulation",children:"LiDAR Simulation"}),"\n",(0,s.jsx)(e.p,{children:"LiDAR (Light Detection and Ranging) sensors are crucial for navigation and mapping. Gazebo supports both 2D and 3D LiDAR simulation."}),"\n",(0,s.jsx)(e.h3,{id:"2d-lidar-configuration",children:"2D LiDAR Configuration"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-xml",children:'<sensor name="laser" type="ray">\n  <always_on>true</always_on>\n  <update_rate>10</update_rate>\n  <ray>\n    <scan>\n      <horizontal>\n        <samples>720</samples>\n        <resolution>1</resolution>\n        <min_angle>-1.570796</min_angle> \x3c!-- -90 degrees --\x3e\n        <max_angle>1.570796</max_angle>   \x3c!-- 90 degrees --\x3e\n      </horizontal>\n    </scan>\n    <range>\n      <min>0.1</min>\n      <max>30.0</max>\n      <resolution>0.01</resolution>\n    </range>\n  </ray>\n  <plugin name="laser_scan" filename="libgazebo_ros_ray_sensor.so">\n    <ros>\n      <argument>~/out:=scan</argument>\n    </ros>\n    <output_type>sensor_msgs/LaserScan</output_type>\n  </plugin>\n</sensor>\n'})}),"\n",(0,s.jsx)(e.h3,{id:"3d-lidar-configuration-hdl-32e-example",children:"3D LiDAR Configuration (HDL-32E Example)"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-xml",children:'<sensor name="velodyne" type="ray">\n  <always_on>true</always_on>\n  <update_rate>10</update_rate>\n  <ray>\n    <scan>\n      <horizontal>\n        <samples>1024</samples>\n        <resolution>1</resolution>\n        <min_angle>-3.14159265</min_angle>\n        <max_angle>3.14159265</max_angle>\n      </horizontal>\n      <vertical>\n        <samples>32</samples>\n        <resolution>1</resolution>\n        <min_angle>-0.523599</min_angle> \x3c!-- -30 degrees --\x3e\n        <max_angle>0.157080</max_angle>   \x3c!-- 9 degrees --\x3e\n      </vertical>\n    </scan>\n    <range>\n      <min>0.1</min>\n      <max>100.0</max>\n      <resolution>0.01</resolution>\n    </range>\n  </ray>\n  <plugin name="velodyne_controller" filename="libgazebo_ros_velodyne_gpu_laser.so">\n    <topic_name>velodyne_points</topic_name>\n    <frame_name>velodyne</frame_name>\n    <min_range>0.1</min_range>\n    <max_range>100.0</max_range>\n    <gaussian_noise>0.01</gaussian_noise>\n  </plugin>\n</sensor>\n'})}),"\n",(0,s.jsx)(e.h2,{id:"imu-simulation",children:"IMU Simulation"}),"\n",(0,s.jsx)(e.p,{children:"Inertial Measurement Units (IMUs) provide orientation, velocity, and gravitational data. Gazebo simulates IMUs with realistic noise characteristics."}),"\n",(0,s.jsx)(e.h3,{id:"imu-sdf-configuration",children:"IMU SDF Configuration"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-xml",children:'<sensor name="imu_sensor" type="imu">\n  <always_on>true</always_on>\n  <update_rate>100</update_rate>\n  <imu>\n    <angular_velocity>\n      <x>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>2e-4</stddev>\n          <bias_mean>0.0000075</bias_mean>\n          <bias_stddev>0.0000008</bias_stddev>\n        </noise>\n      </x>\n      <y>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>2e-4</stddev>\n          <bias_mean>0.0000075</bias_mean>\n          <bias_stddev>0.0000008</bias_stddev>\n        </noise>\n      </y>\n      <z>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>2e-4</stddev>\n          <bias_mean>0.0000075</bias_mean>\n          <bias_stddev>0.0000008</bias_stddev>\n        </noise>\n      </z>\n    </angular_velocity>\n    <linear_acceleration>\n      <x>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>1.7e-2</stddev>\n          <bias_mean>0.1</bias_mean>\n          <bias_stddev>0.001</bias_stddev>\n        </noise>\n      </x>\n      <y>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>1.7e-2</stddev>\n          <bias_mean>0.1</bias_mean>\n          <bias_stddev>0.001</bias_stddev>\n        </noise>\n      </y>\n      <z>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>1.7e-2</stddev>\n          <bias_mean>0.1</bias_mean>\n          <bias_stddev>0.001</bias_stddev>\n        </noise>\n      </z>\n    </linear_acceleration>\n  </imu>\n  <plugin name="imu_plugin" filename="libgazebo_ros_imu.so">\n    <ros>\n      <argument>~/out:=imu/data</argument>\n    </ros>\n    <frame_name>imu_link</frame_name>\n    <body_name>imu_body</body_name>\n  </plugin>\n</sensor>\n'})}),"\n",(0,s.jsx)(e.h2,{id:"gps-simulation",children:"GPS Simulation"}),"\n",(0,s.jsx)(e.p,{children:"GPS sensors provide global position information, useful for outdoor robotics applications."}),"\n",(0,s.jsx)(e.h3,{id:"gps-sdf-configuration",children:"GPS SDF Configuration"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-xml",children:'<sensor name="gps_sensor" type="gps">\n  <always_on>true</always_on>\n  <update_rate>10</update_rate>\n  <plugin name="gps_plugin" filename="libgazebo_ros_gps.so">\n    <ros>\n      <argument>~/out:=gps/fix</argument>\n    </ros>\n    <frame_name>gps_link</frame_name>\n    <topic_name>gps/fix</topic_name>\n    <gaussian_noise>0.1</gaussian_noise>\n  </plugin>\n</sensor>\n'})}),"\n",(0,s.jsx)(e.h2,{id:"forcetorque-sensor-simulation",children:"Force/Torque Sensor Simulation"}),"\n",(0,s.jsx)(e.p,{children:"Force/torque sensors are essential for manipulation tasks, providing information about contact forces."}),"\n",(0,s.jsx)(e.h3,{id:"forcetorque-sdf-configuration",children:"Force/Torque SDF Configuration"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-xml",children:'<sensor name="ft_sensor" type="force_torque">\n  <always_on>true</always_on>\n  <update_rate>100</update_rate>\n  <plugin name="ft_plugin" filename="libgazebo_ros_ft_sensor.so">\n    <ros>\n      <argument>~/out:=ft_sensor/wrench</argument>\n    </ros>\n    <frame_name>ft_sensor_link</frame_name>\n    <topic_name>ft_sensor/wrench</topic_name>\n  </plugin>\n</sensor>\n'})}),"\n",(0,s.jsx)(e.h2,{id:"complete-robot-model-with-sensors",children:"Complete Robot Model with Sensors"}),"\n",(0,s.jsx)(e.p,{children:"Here's an example of a robot model with multiple sensors:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-xml",children:'<?xml version="1.0" ?>\n<robot name="sensor_robot" xmlns:xacro="http://www.ros.org/wiki/xacro">\n  \x3c!-- Base Link --\x3e\n  <link name="base_link">\n    <visual>\n      <geometry>\n        <box size="0.5 0.3 0.2"/>\n      </geometry>\n    </visual>\n    <collision>\n      <geometry>\n        <box size="0.5 0.3 0.2"/>\n      </geometry>\n    </collision>\n    <inertial>\n      <mass value="5.0"/>\n      <inertia ixx="0.1" ixy="0.0" ixz="0.0" iyy="0.2" iyz="0.0" izz="0.3"/>\n    </inertial>\n  </link>\n\n  \x3c!-- Camera Mount --\x3e\n  <joint name="camera_joint" type="fixed">\n    <parent link="base_link"/>\n    <child link="camera_link"/>\n    <origin xyz="0.2 0 0.1" rpy="0 0 0"/>\n  </joint>\n\n  <link name="camera_link">\n    <visual>\n      <geometry>\n        <box size="0.05 0.05 0.05"/>\n      </geometry>\n    </visual>\n  </link>\n\n  \x3c!-- Camera Sensor --\x3e\n  <gazebo reference="camera_link">\n    <sensor name="camera" type="camera">\n      <always_on>true</always_on>\n      <update_rate>30</update_rate>\n      <camera name="head">\n        <horizontal_fov>1.047</horizontal_fov>\n        <image>\n          <width>640</width>\n          <height>480</height>\n          <format>R8G8B8</format>\n        </image>\n        <clip>\n          <near>0.1</near>\n          <far>100</far>\n        </clip>\n      </camera>\n      <plugin name="camera_controller" filename="libgazebo_ros_camera.so">\n        <frame_name>camera_link</frame_name>\n        <topic_name>camera/image_raw</topic_name>\n      </plugin>\n    </sensor>\n  </gazebo>\n\n  \x3c!-- LiDAR Mount --\x3e\n  <joint name="lidar_joint" type="fixed">\n    <parent link="base_link"/>\n    <child link="lidar_link"/>\n    <origin xyz="0.1 0 0.2" rpy="0 0 0"/>\n  </joint>\n\n  <link name="lidar_link">\n    <visual>\n      <geometry>\n        <cylinder radius="0.05" length="0.05"/>\n      </geometry>\n    </visual>\n  </link>\n\n  \x3c!-- LiDAR Sensor --\x3e\n  <gazebo reference="lidar_link">\n    <sensor name="laser" type="ray">\n      <always_on>true</always_on>\n      <update_rate>10</update_rate>\n      <ray>\n        <scan>\n          <horizontal>\n            <samples>720</samples>\n            <resolution>1</resolution>\n            <min_angle>-1.570796</min_angle>\n            <max_angle>1.570796</max_angle>\n          </horizontal>\n        </scan>\n        <range>\n          <min>0.1</min>\n          <max>30.0</max>\n          <resolution>0.01</resolution>\n        </range>\n      </ray>\n      <plugin name="laser_scan" filename="libgazebo_ros_ray_sensor.so">\n        <ros>\n          <argument>~/out:=scan</argument>\n        </ros>\n        <output_type>sensor_msgs/LaserScan</output_type>\n      </plugin>\n    </sensor>\n  </gazebo>\n\n  \x3c!-- IMU Mount --\x3e\n  <joint name="imu_joint" type="fixed">\n    <parent link="base_link"/>\n    <child link="imu_link"/>\n    <origin xyz="0 0 0.1" rpy="0 0 0"/>\n  </joint>\n\n  <link name="imu_link">\n    <visual>\n      <geometry>\n        <box size="0.02 0.02 0.02"/>\n      </geometry>\n    </visual>\n  </link>\n\n  \x3c!-- IMU Sensor --\x3e\n  <gazebo reference="imu_link">\n    <sensor name="imu_sensor" type="imu">\n      <always_on>true</always_on>\n      <update_rate>100</update_rate>\n      <plugin name="imu_plugin" filename="libgazebo_ros_imu.so">\n        <ros>\n          <argument>~/out:=imu/data</argument>\n        </ros>\n        <frame_name>imu_link</frame_name>\n      </plugin>\n    </sensor>\n  </gazebo>\n</robot>\n'})}),"\n",(0,s.jsx)(e.h2,{id:"practical-exercise-sensor-integration",children:"Practical Exercise: Sensor Integration"}),"\n",(0,s.jsx)(e.p,{children:"Create a robot model with at least 3 different sensor types and test their functionality:"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsx)(e.li,{children:"Create a URDF file with a simple robot base"}),"\n",(0,s.jsx)(e.li,{children:"Add camera, LiDAR, and IMU sensors"}),"\n",(0,s.jsx)(e.li,{children:"Load the robot in Gazebo"}),"\n",(0,s.jsx)(e.li,{children:"Verify that sensor data is published on ROS topics"}),"\n",(0,s.jsx)(e.li,{children:"Visualize the sensor data using RViz"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Commands to test:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:'# Launch Gazebo with your robot\nros2 launch your_package your_launch_file.py\n\n# Check available topics\nros2 topic list | grep -E "(camera|scan|imu)"\n\n# View sensor data\nros2 topic echo /camera/image_raw\nros2 topic echo /scan\nros2 topic echo /imu/data\n'})}),"\n",(0,s.jsx)(e.h2,{id:"sensor-noise-and-realism",children:"Sensor Noise and Realism"}),"\n",(0,s.jsx)(e.p,{children:"Real sensors have noise and imperfections. When simulating sensors:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Add realistic noise models"})," that match real sensor specifications"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Consider environmental factors"})," like lighting conditions for cameras"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Validate sensor performance"})," against real hardware when possible"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Use domain randomization"})," to make algorithms robust to sensor variations"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"troubleshooting-sensor-issues",children:"Troubleshooting Sensor Issues"}),"\n",(0,s.jsx)(e.h3,{id:"sensor-data-not-publishing",children:"Sensor Data Not Publishing"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Check that the Gazebo ROS plugin is loaded"}),"\n",(0,s.jsx)(e.li,{children:"Verify topic names and frame IDs"}),"\n",(0,s.jsx)(e.li,{children:"Ensure the sensor is properly attached to a link"}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"performance-issues",children:"Performance Issues"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Reduce sensor update rates"}),"\n",(0,s.jsx)(e.li,{children:"Lower resolution for cameras"}),"\n",(0,s.jsx)(e.li,{children:"Decrease the number of LiDAR rays"}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"inaccurate-data",children:"Inaccurate Data"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Check sensor mounting position and orientation"}),"\n",(0,s.jsx)(e.li,{children:"Verify noise parameters"}),"\n",(0,s.jsx)(e.li,{children:"Validate physics properties of the environment"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,s.jsx)(e.p,{children:"This lesson covered sensor simulation in Gazebo, including cameras, LiDAR, IMUs, and other sensor types. Understanding sensor simulation is crucial for developing and testing perception algorithms in robotics."}),"\n",(0,s.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsx)(e.p,{children:"In the next lesson, we'll explore the integration between Gazebo and ROS 2, learning how to control simulated robots and process sensor data."})]})}function m(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(c,{...n})}):c(n)}},8453:(n,e,a)=>{a.d(e,{R:()=>r,x:()=>t});var i=a(6540);const s={},o=i.createContext(s);function r(n){const e=i.useContext(o);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function t(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:r(n.components),i.createElement(o.Provider,{value:e},n.children)}}}]);