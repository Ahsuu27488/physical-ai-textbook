"use strict";(globalThis.webpackChunkmy_website_1=globalThis.webpackChunkmy_website_1||[]).push([[4865],{4076:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>c,contentTitle:()=>r,default:()=>m,frontMatter:()=>i,metadata:()=>a,toc:()=>l});const a=JSON.parse('{"id":"module-4/lesson-2-cognitive-planning","title":"Lesson 2 - Cognitive Planning and Action Generation","description":"Learning Objectives","source":"@site/docs/module-4/lesson-2-cognitive-planning.md","sourceDirName":"module-4","slug":"/module-4/lesson-2-cognitive-planning","permalink":"/docs/module-4/lesson-2-cognitive-planning","draft":false,"unlisted":false,"editUrl":"https://github.com/Ahsuu27488/physical-ai-textbook/tree/main/frontend/docs/module-4/lesson-2-cognitive-planning.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"title":"Lesson 2 - Cognitive Planning and Action Generation","sidebar_position":5},"sidebar":"textbookSidebar","previous":{"title":"Lesson 1 - Vision-Language Fundamentals","permalink":"/docs/module-4/lesson-1-vision-language-fundamentals"},"next":{"title":"Lesson 3 - VLA Integration and Autonomous Systems","permalink":"/docs/module-4/lesson-3-vla-integration"}}');var s=t(4848),o=t(8453);const i={title:"Lesson 2 - Cognitive Planning and Action Generation",sidebar_position:5},r="Lesson 2: Cognitive Planning and Action Generation",c={},l=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction to Cognitive Planning",id:"introduction-to-cognitive-planning",level:2},{value:"Key Components of Cognitive Planning",id:"key-components-of-cognitive-planning",level:3},{value:"Natural Language Understanding for Robotics",id:"natural-language-understanding-for-robotics",level:2},{value:"Command Parsing",id:"command-parsing",level:3},{value:"Semantic Role Labeling",id:"semantic-role-labeling",level:3},{value:"Task Decomposition",id:"task-decomposition",level:2},{value:"Action Libraries and Robot Capabilities",id:"action-libraries-and-robot-capabilities",level:2},{value:"Planning and Execution Framework",id:"planning-and-execution-framework",level:2},{value:"Integration with Large Language Models",id:"integration-with-large-language-models",level:2},{value:"Complete Cognitive Planning System",id:"complete-cognitive-planning-system",level:2},{value:"Practical Exercise: Implement a Simple Command System",id:"practical-exercise-implement-a-simple-command-system",level:2},{value:"Example Implementation Structure:",id:"example-implementation-structure",level:3},{value:"Summary",id:"summary",level:2},{value:"Next Steps",id:"next-steps",level:2}];function p(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"lesson-2-cognitive-planning-and-action-generation",children:"Lesson 2: Cognitive Planning and Action Generation"})}),"\n",(0,s.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,s.jsx)(e.p,{children:"By the end of this lesson, students will be able to:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Implement cognitive planning systems that translate natural language to robot actions"}),"\n",(0,s.jsx)(e.li,{children:"Design action libraries for robotic systems"}),"\n",(0,s.jsx)(e.li,{children:"Create task decomposition algorithms"}),"\n",(0,s.jsx)(e.li,{children:"Integrate language models with robot control systems"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"introduction-to-cognitive-planning",children:"Introduction to Cognitive Planning"}),"\n",(0,s.jsx)(e.p,{children:"Cognitive planning is the process of converting high-level natural language commands into executable robotic actions. This involves understanding the command, decomposing it into subtasks, planning the sequence of actions, and executing them on the robot."}),"\n",(0,s.jsx)(e.h3,{id:"key-components-of-cognitive-planning",children:"Key Components of Cognitive Planning"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Natural Language Understanding"}),": Parsing and interpreting human commands"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Task Decomposition"}),": Breaking complex tasks into simpler subtasks"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Action Planning"}),": Sequencing actions to achieve the goal"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Execution Monitoring"}),": Tracking progress and handling failures"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Feedback Generation"}),": Communicating with the human operator"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"natural-language-understanding-for-robotics",children:"Natural Language Understanding for Robotics"}),"\n",(0,s.jsx)(e.h3,{id:"command-parsing",children:"Command Parsing"}),"\n",(0,s.jsx)(e.p,{children:"Natural language commands for robots often follow patterns that can be parsed:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"import re\nfrom typing import Dict, List, Tuple\n\nclass CommandParser:\n    def __init__(self):\n        # Define action patterns\n        self.patterns = {\n            'move': [\n                r'move to (.+)',\n                r'go to (.+)',\n                r'go to the (.+)',\n                r'approach (.+)',\n                r'navigate to (.+)'\n            ],\n            'grasp': [\n                r'pick up (.+)',\n                r'grasp (.+)',\n                r'grab (.+)',\n                r'get (.+)',\n                r'take (.+)'\n            ],\n            'place': [\n                r'put (.+) on (.+)',\n                r'place (.+) on (.+)',\n                r'place (.+) at (.+)',\n                r'put (.+) in (.+)'\n            ],\n            'clean': [\n                r'clean (.+)',\n                r'wipe (.+)',\n                r'clean up (.+)'\n            ]\n        }\n\n    def parse_command(self, command: str) -> Dict:\n        \"\"\"Parse a natural language command into structured action\"\"\"\n        command_lower = command.lower().strip()\n\n        for action_type, patterns in self.patterns.items():\n            for pattern in patterns:\n                match = re.search(pattern, command_lower)\n                if match:\n                    # Extract parameters based on pattern groups\n                    params = match.groups()\n                    return {\n                        'action': action_type,\n                        'parameters': params,\n                        'original_command': command\n                    }\n\n        # If no pattern matches, return as unknown\n        return {\n            'action': 'unknown',\n            'parameters': [command],\n            'original_command': command\n        }\n\n# Example usage\nparser = CommandParser()\ncommand = \"Please pick up the red cup and place it on the table\"\nresult = parser.parse_command(command)\nprint(f\"Parsed command: {result}\")\n"})}),"\n",(0,s.jsx)(e.h3,{id:"semantic-role-labeling",children:"Semantic Role Labeling"}),"\n",(0,s.jsx)(e.p,{children:"For more complex understanding, we can use semantic role labeling:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"import spacy\n\nclass SemanticParser:\n    def __init__(self):\n        # Load spaCy model with NER and parsing\n        self.nlp = spacy.load(\"en_core_web_sm\")\n\n    def extract_entities_and_roles(self, command: str) -> Dict:\n        \"\"\"Extract entities and their roles from command\"\"\"\n        doc = self.nlp(command)\n\n        entities = {}\n        for ent in doc.ents:\n            entities[ent.text] = {\n                'label': ent.label_,\n                'description': self.get_entity_description(ent.label_)\n            }\n\n        # Extract action verbs\n        verbs = []\n        for token in doc:\n            if token.pos_ == \"VERB\":\n                verbs.append({\n                    'text': token.text,\n                    'lemma': token.lemma_,\n                    'children': [child.text for child in token.children]\n                })\n\n        return {\n            'entities': entities,\n            'verbs': verbs,\n            'pos_tags': [(token.text, token.pos_) for token in doc]\n        }\n\n    def get_entity_description(self, label: str) -> str:\n        \"\"\"Get description for entity label\"\"\"\n        descriptions = {\n            'PERSON': 'Person or character',\n            'NORP': 'Nationalities, religious or political groups',\n            'FAC': 'Buildings, airports, highways, bridges',\n            'ORG': 'Companies, agencies, institutions',\n            'GPE': 'Countries, cities, states',\n            'LOC': 'Non-GPE locations',\n            'PRODUCT': 'Objects, vehicles, foods',\n            'EVENT': 'Named hurricanes, battles, etc.',\n            'WORK_OF_ART': 'Titles of books, songs',\n            'LAW': 'Named documents',\n            'LANGUAGE': 'Any named language'\n        }\n        return descriptions.get(label, 'Unknown entity type')\n"})}),"\n",(0,s.jsx)(e.h2,{id:"task-decomposition",children:"Task Decomposition"}),"\n",(0,s.jsx)(e.p,{children:"Complex commands need to be broken down into simpler, executable subtasks:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"class TaskDecomposer:\n    def __init__(self):\n        self.action_library = {\n            'pick_up': ['approach_object', 'grasp_object', 'lift_object'],\n            'place_object': ['approach_location', 'lower_object', 'release_object'],\n            'clean_surface': ['approach_surface', 'wipe_surface', 'retreat'],\n            'navigate': ['path_planning', 'move_to_pose', 'localize']\n        }\n\n    def decompose_task(self, parsed_command: Dict) -> List[Dict]:\n        \"\"\"Decompose a high-level task into subtasks\"\"\"\n        action = parsed_command['action']\n        params = parsed_command['parameters']\n\n        if action == 'place':\n            # \"place X on Y\" -> pick up X, navigate to Y, place X\n            object_to_place = params[0] if len(params) > 0 else 'object'\n            target_location = params[1] if len(params) > 1 else 'location'\n\n            subtasks = [\n                {\n                    'action': 'find_object',\n                    'parameters': {'object_name': object_to_place},\n                    'description': f'Locate the {object_to_place}'\n                },\n                {\n                    'action': 'pick_up',\n                    'parameters': {'object_name': object_to_place},\n                    'description': f'Pick up the {object_to_place}'\n                },\n                {\n                    'action': 'find_location',\n                    'parameters': {'location_name': target_location},\n                    'description': f'Locate the {target_location}'\n                },\n                {\n                    'action': 'navigate',\n                    'parameters': {'target': target_location},\n                    'description': f'Navigate to the {target_location}'\n                },\n                {\n                    'action': 'place_object',\n                    'parameters': {'object_name': object_to_place, 'location': target_location},\n                    'description': f'Place the {object_to_place} on the {target_location}'\n                }\n            ]\n        elif action == 'clean':\n            target_surface = params[0] if len(params) > 0 else 'surface'\n            subtasks = [\n                {\n                    'action': 'find_surface',\n                    'parameters': {'surface_name': target_surface},\n                    'description': f'Locate the {target_surface}'\n                },\n                {\n                    'action': 'approach_surface',\n                    'parameters': {'surface_name': target_surface},\n                    'description': f'Approach the {target_surface}'\n                },\n                {\n                    'action': 'clean_surface',\n                    'parameters': {'surface_name': target_surface},\n                    'description': f'Clean the {target_surface}'\n                },\n                {\n                    'action': 'retreat',\n                    'parameters': {},\n                    'description': 'Move away from the cleaned surface'\n                }\n            ]\n        else:\n            # For simple actions, decompose using action library\n            if action in self.action_library:\n                subtasks = []\n                for sub_action in self.action_library[action]:\n                    subtasks.append({\n                        'action': sub_action,\n                        'parameters': parsed_command['parameters'],\n                        'description': f'Execute {sub_action} for the given parameters'\n                    })\n            else:\n                # Single action if not in library\n                subtasks = [parsed_command]\n\n        return subtasks\n\n# Example usage\ndecomposer = TaskDecomposer()\nparsed_cmd = {'action': 'place', 'parameters': ['red cup', 'table']}\nsubtasks = decomposer.decompose_task(parsed_cmd)\nfor i, task in enumerate(subtasks):\n    print(f\"{i+1}. {task['description']}\")\n"})}),"\n",(0,s.jsx)(e.h2,{id:"action-libraries-and-robot-capabilities",children:"Action Libraries and Robot Capabilities"}),"\n",(0,s.jsx)(e.p,{children:"Define what actions the robot can perform:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"from abc import ABC, abstractmethod\nfrom typing import Any, Dict, List\nimport asyncio\n\nclass RobotAction(ABC):\n    \"\"\"Base class for robot actions\"\"\"\n\n    def __init__(self, name: str, description: str):\n        self.name = name\n        self.description = description\n\n    @abstractmethod\n    async def execute(self, parameters: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Execute the action with given parameters\"\"\"\n        pass\n\n    def validate_parameters(self, parameters: Dict[str, Any]) -> bool:\n        \"\"\"Validate action parameters\"\"\"\n        return True\n\nclass NavigationAction(RobotAction):\n    def __init__(self):\n        super().__init__(\"navigate\", \"Move the robot to a specified location\")\n\n    async def execute(self, parameters: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Execute navigation action\"\"\"\n        target = parameters.get('target', parameters.get('pose'))\n        if not target:\n            return {'success': False, 'error': 'No target specified'}\n\n        # Simulate navigation\n        print(f\"Navigating to {target}\")\n\n        # In real implementation, this would interface with navigation stack\n        # await self.navigation_client.go_to_pose(target)\n\n        # Simulate execution time\n        await asyncio.sleep(2.0)\n\n        return {\n            'success': True,\n            'message': f'Reached {target}',\n            'executed_action': 'navigate',\n            'parameters': parameters\n        }\n\nclass GraspingAction(RobotAction):\n    def __init__(self):\n        super().__init__(\"grasp_object\", \"Grasp an object with the robot's end-effector\")\n\n    async def execute(self, parameters: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Execute grasping action\"\"\"\n        object_name = parameters.get('object_name', 'object')\n        approach_height = parameters.get('approach_height', 0.1)\n\n        print(f\"Attempting to grasp {object_name}\")\n\n        # In real implementation, this would:\n        # 1. Find object in robot coordinates\n        # 2. Plan grasp trajectory\n        # 3. Execute grasp\n        # 4. Verify grasp success\n\n        # Simulate execution\n        await asyncio.sleep(3.0)\n\n        success = True  # In real implementation, check grasp success\n\n        return {\n            'success': success,\n            'message': f'Grasp of {object_name} {\"succeeded\" if success else \"failed\"}',\n            'executed_action': 'grasp_object',\n            'parameters': parameters\n        }\n\nclass ActionLibrary:\n    def __init__(self):\n        self.actions = {\n            'navigate': NavigationAction(),\n            'grasp_object': GraspingAction(),\n            # Add more actions as needed\n            'approach_object': NavigationAction(),\n            'approach_location': NavigationAction(),\n            'place_object': GraspingAction(),  # Simplified for example\n            'lift_object': GraspingAction(),\n            'release_object': GraspingAction(),\n            'wipe_surface': RobotAction(\"wipe_surface\", \"Wipe a surface\"),\n            'lower_object': GraspingAction(),\n            'retreat': NavigationAction(),\n            'path_planning': RobotAction(\"path_planning\", \"Plan a path to target\"),\n            'move_to_pose': NavigationAction(),\n            'localize': RobotAction(\"localize\", \"Localize the robot in the environment\"),\n            'find_object': RobotAction(\"find_object\", \"Locate an object in the environment\"),\n            'find_location': RobotAction(\"find_location\", \"Locate a specific location\"),\n            'approach_surface': NavigationAction(),\n            'clean_surface': RobotAction(\"clean_surface\", \"Clean a surface\")\n        }\n\n    async def execute_action(self, action_name: str, parameters: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Execute a named action with parameters\"\"\"\n        if action_name not in self.actions:\n            return {\n                'success': False,\n                'error': f'Action {action_name} not found in library'\n            }\n\n        action = self.actions[action_name]\n        if not action.validate_parameters(parameters):\n            return {\n                'success': False,\n                'error': f'Invalid parameters for action {action_name}'\n            }\n\n        try:\n            result = await action.execute(parameters)\n            return result\n        except Exception as e:\n            return {\n                'success': False,\n                'error': f'Execution failed: {str(e)}'\n            }\n"})}),"\n",(0,s.jsx)(e.h2,{id:"planning-and-execution-framework",children:"Planning and Execution Framework"}),"\n",(0,s.jsx)(e.p,{children:"Create a framework to plan and execute sequences of actions:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"import asyncio\nfrom dataclasses import dataclass\nfrom enum import Enum\nfrom typing import List, Optional\n\nclass ExecutionStatus(Enum):\n    PENDING = \"pending\"\n    RUNNING = \"running\"\n    SUCCESS = \"success\"\n    FAILED = \"failed\"\n    CANCELLED = \"cancelled\"\n\n@dataclass\nclass Task:\n    action: str\n    parameters: Dict[str, Any]\n    description: str\n    dependencies: List[str] = None\n\nclass PlanExecutor:\n    def __init__(self, action_library: ActionLibrary):\n        self.action_library = action_library\n        self.current_plan = []\n        self.execution_history = []\n        self.status = ExecutionStatus.PENDING\n\n    async def execute_plan(self, tasks: List[Dict]) -> Dict[str, Any]:\n        \"\"\"Execute a sequence of tasks\"\"\"\n        self.status = ExecutionStatus.RUNNING\n        self.execution_history = []\n        results = []\n\n        for i, task_data in enumerate(tasks):\n            print(f\"Executing task {i+1}/{len(tasks)}: {task_data['description']}\")\n\n            result = await self.action_library.execute_action(\n                task_data['action'],\n                task_data['parameters']\n            )\n\n            task_result = {\n                'task_index': i,\n                'task_description': task_data['description'],\n                'result': result,\n                'timestamp': asyncio.get_event_loop().time()\n            }\n\n            self.execution_history.append(task_result)\n            results.append(result)\n\n            # Check if task failed\n            if not result['success']:\n                self.status = ExecutionStatus.FAILED\n                return {\n                    'success': False,\n                    'completed_tasks': len(results),\n                    'total_tasks': len(tasks),\n                    'error': result.get('error', 'Task failed'),\n                    'results': results\n                }\n\n        self.status = ExecutionStatus.SUCCESS\n        return {\n            'success': True,\n            'completed_tasks': len(results),\n            'total_tasks': len(tasks),\n            'results': results\n        }\n\n    async def execute_with_monitoring(self, tasks: List[Dict], timeout: float = 300.0) -> Dict[str, Any]:\n        \"\"\"Execute plan with timeout and monitoring\"\"\"\n        try:\n            # Create a timeout task\n            execution_task = asyncio.create_task(self.execute_plan(tasks))\n            result = await asyncio.wait_for(execution_task, timeout=timeout)\n            return result\n        except asyncio.TimeoutError:\n            self.status = ExecutionStatus.CANCELLED\n            return {\n                'success': False,\n                'completed_tasks': len(self.execution_history),\n                'error': 'Execution timed out',\n                'results': [item['result'] for item in self.execution_history]\n            }\n"})}),"\n",(0,s.jsx)(e.h2,{id:"integration-with-large-language-models",children:"Integration with Large Language Models"}),"\n",(0,s.jsx)(e.p,{children:"Connect the planning system with LLMs for more sophisticated understanding:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'import openai\nimport json\nfrom typing import Dict, Any\n\nclass LLMPlanner:\n    def __init__(self, api_key: str):\n        openai.api_key = api_key\n        self.action_descriptions = {\n            \'navigate\': \'Move the robot to a specified location\',\n            \'grasp_object\': \'Grasp an object with the robot\\\'s end-effector\',\n            \'place_object\': \'Place an object at a specified location\',\n            \'find_object\': \'Locate an object in the environment\',\n            \'find_location\': \'Locate a specific location in the environment\',\n            \'clean_surface\': \'Clean a surface\',\n            \'approach_object\': \'Move close to an object\',\n            \'approach_location\': \'Move close to a location\',\n            \'lift_object\': \'Lift an object after grasping\',\n            \'release_object\': \'Release a grasped object\',\n            \'wipe_surface\': \'Wipe a surface clean\',\n            \'lower_object\': \'Lower an object\',\n            \'retreat\': \'Move away from current position\'\n        }\n\n    def get_available_actions_prompt(self) -> str:\n        """Get prompt describing available actions"""\n        actions_str = "\\n".join([\n            f"- {action}: {desc}"\n            for action, desc in self.action_descriptions.items()\n        ])\n        return f"""\nAvailable robot actions:\n{actions_str}\n\nEach action should have appropriate parameters like object names, locations, etc.\n"""\n\n    async def plan_from_command(self, command: str, world_state: Dict[str, Any] = None) -> List[Dict]:\n        """Generate a plan from natural language command using LLM"""\n        prompt = f"""\nYou are a robot task planner. Convert the following natural language command into a sequence of executable robot actions.\n\n{self.get_available_actions_prompt()}\n\nCurrent world state: {json.dumps(world_state, indent=2) if world_state else \'Unknown\'}\n\nCommand: "{command}"\n\nPlease respond with a JSON list of tasks, where each task has:\n- "action": the action name\n- "parameters": a dictionary of parameters\n- "description": human-readable description\n\nExample response format:\n[\n    {{\n        "action": "find_object",\n        "parameters": {{"object_name": "red cup"}},\n        "description": "Locate the red cup in the environment"\n    }},\n    {{\n        "action": "approach_object",\n        "parameters": {{"object_name": "red cup"}},\n        "description": "Move close to the red cup"\n    }}\n]\n\nResponse (JSON only, no other text):\n"""\n\n        try:\n            response = openai.ChatCompletion.create(\n                model="gpt-3.5-turbo",\n                messages=[{"role": "user", "content": prompt}],\n                temperature=0.1,\n                max_tokens=1000\n            )\n\n            # Extract JSON from response\n            response_text = response.choices[0].message[\'content\'].strip()\n\n            # Clean up response if it contains markdown code blocks\n            if response_text.startswith(\'```json\'):\n                response_text = response_text[7:]  # Remove ```json\n            if response_text.endswith(\'```\'):\n                response_text = response_text[:-3]  # Remove ```\n\n            plan = json.loads(response_text)\n            return plan\n        except Exception as e:\n            print(f"Error generating plan with LLM: {e}")\n            # Fallback to simple parsing\n            parser = CommandParser()\n            parsed = parser.parse_command(command)\n            decomposer = TaskDecomposer()\n            fallback_plan = decomposer.decompose_task(parsed)\n            return fallback_plan\n'})}),"\n",(0,s.jsx)(e.h2,{id:"complete-cognitive-planning-system",children:"Complete Cognitive Planning System"}),"\n",(0,s.jsx)(e.p,{children:"Putting it all together:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'class CognitivePlanningSystem:\n    def __init__(self, llm_api_key: str = None):\n        self.action_library = ActionLibrary()\n        self.executor = PlanExecutor(self.action_library)\n        self.llm_planner = LLMPlanner(llm_api_key) if llm_api_key else None\n        self.command_parser = CommandParser()\n        self.task_decomposer = TaskDecomposer()\n\n    async def execute_command(self, command: str, world_state: Dict[str, Any] = None) -> Dict[str, Any]:\n        """Execute a natural language command end-to-end"""\n        print(f"Processing command: {command}")\n\n        # Generate plan (either with LLM or simple decomposition)\n        if self.llm_planner:\n            plan = await self.llm_planner.plan_from_command(command, world_state)\n        else:\n            # Fallback to simple parsing and decomposition\n            parsed = self.command_parser.parse_command(command)\n            plan = self.task_decomposer.decompose_task(parsed)\n\n        print(f"Generated plan with {len(plan)} tasks")\n        for i, task in enumerate(plan):\n            print(f"  {i+1}. {task[\'description\']}")\n\n        # Execute the plan\n        result = await self.executor.execute_with_monitoring(plan)\n\n        return {\n            \'command\': command,\n            \'plan\': plan,\n            \'execution_result\': result,\n            \'success\': result[\'success\']\n        }\n\n# Example usage\nasync def main():\n    # Initialize the system (you would provide a real API key)\n    system = CognitivePlanningSystem()  # llm_api_key="your-api-key"\n\n    # Example commands\n    commands = [\n        "Pick up the red cup and place it on the table",\n        "Clean the kitchen counter",\n        "Go to the living room and find the blue book"\n    ]\n\n    for cmd in commands:\n        print(f"\\n--- Executing: {cmd} ---")\n        result = await system.execute_command(cmd)\n        print(f"Success: {result[\'success\']}")\n        print(f"Completed {result[\'execution_result\'][\'completed_tasks\']} of {result[\'execution_result\'][\'total_tasks\']} tasks")\n\n# To run: asyncio.run(main())\n'})}),"\n",(0,s.jsx)(e.h2,{id:"practical-exercise-implement-a-simple-command-system",children:"Practical Exercise: Implement a Simple Command System"}),"\n",(0,s.jsx)(e.p,{children:"Create a simplified cognitive planning system:"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Create action classes"})," for basic robot capabilities"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Implement command parsing"})," for common robot commands"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Build a task decomposer"})," that breaks complex commands into simple actions"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Create a plan executor"})," that runs the sequence of actions"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Test with sample commands"}),' like "pick up the ball" or "go to the kitchen"']}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"example-implementation-structure",children:"Example Implementation Structure:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"class SimpleCognitivePlanner:\n    def __init__(self):\n        self.actions = {\n            'move': self.execute_move,\n            'grasp': self.execute_grasp,\n            'release': self.execute_release,\n            'find': self.execute_find\n        }\n\n    async def execute_move(self, params):\n        location = params.get('location', 'unknown')\n        print(f\"Moving to {location}\")\n        await asyncio.sleep(1)  # Simulate movement\n        return {'success': True, 'location': location}\n\n    async def execute_grasp(self, params):\n        object_name = params.get('object', 'unknown object')\n        print(f\"Grasping {object_name}\")\n        await asyncio.sleep(1)  # Simulate grasping\n        return {'success': True, 'object': object_name}\n\n    # Add other action methods...\n\n    async def process_command(self, command):\n        # Parse, plan, and execute the command\n        pass\n"})}),"\n",(0,s.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,s.jsx)(e.p,{children:"This lesson covered cognitive planning systems that translate natural language commands into robot actions. We explored command parsing, task decomposition, action libraries, and integration with language models. Cognitive planning is essential for creating robots that can understand and execute complex human instructions."}),"\n",(0,s.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsx)(e.p,{children:"In the next lesson, we'll explore how to integrate these planning systems with ROS 2 for real-world robotic applications and create the complete Vision-Language-Action pipeline."})]})}function m(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(p,{...n})}):p(n)}},8453:(n,e,t)=>{t.d(e,{R:()=>i,x:()=>r});var a=t(6540);const s={},o=a.createContext(s);function i(n){const e=a.useContext(o);return a.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:i(n.components),a.createElement(o.Provider,{value:e},n.children)}}}]);