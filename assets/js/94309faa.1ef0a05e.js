"use strict";(globalThis.webpackChunkmy_website_1=globalThis.webpackChunkmy_website_1||[]).push([[4770],{8453:(n,e,i)=>{i.d(e,{R:()=>r,x:()=>l});var o=i(6540);const s={},t=o.createContext(s);function r(n){const e=o.useContext(t);return o.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:r(n.components),o.createElement(t.Provider,{value:e},n.children)}},8781:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>a,contentTitle:()=>l,default:()=>h,frontMatter:()=>r,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"week-13/intro","title":"Week 13 - Conversational Robotics","description":"Learning Objectives","source":"@site/docs/week-13/intro.md","sourceDirName":"week-13","slug":"/week-13/intro","permalink":"/physical-ai-textbook/docs/week-13/intro","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/week-13/intro.md","tags":[],"version":"current","sidebarPosition":11,"frontMatter":{"title":"Week 13 - Conversational Robotics","sidebar_position":11,"id":"intro"},"sidebar":"textbookSidebar","previous":{"title":"Weeks 11-12 - Humanoid Robot Development","permalink":"/physical-ai-textbook/docs/week-11-12/intro"}}');var s=i(4848),t=i(8453);const r={title:"Week 13 - Conversational Robotics",sidebar_position:11,id:"intro"},l="Week 13: Conversational Robotics",a={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Topics Covered",id:"topics-covered",level:2},{value:"Key Concepts",id:"key-concepts",level:2},{value:"Conversational AI Integration",id:"conversational-ai-integration",level:3},{value:"Voice-to-Action Pipeline",id:"voice-to-action-pipeline",level:3},{value:"Multi-Modal Integration",id:"multi-modal-integration",level:3},{value:"Capstone Project: The Autonomous Humanoid",id:"capstone-project-the-autonomous-humanoid",level:2},{value:"Practical Exercises",id:"practical-exercises",level:2},{value:"Assignments",id:"assignments",level:2}];function d(n){const e={h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,t.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"week-13-conversational-robotics",children:"Week 13: Conversational Robotics"})}),"\n",(0,s.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,s.jsx)(e.p,{children:"During this final week, students will integrate all the knowledge from previous modules to create conversational robots that can understand natural language commands and execute complex tasks."}),"\n",(0,s.jsx)(e.h2,{id:"topics-covered",children:"Topics Covered"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Integrating GPT models for conversational AI in robots"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Connecting language models to robotic systems"}),"\n",(0,s.jsx)(e.li,{children:"Context management for multi-turn conversations"}),"\n",(0,s.jsx)(e.li,{children:"Safety and filtering for robot commands"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Speech recognition and natural language understanding"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Using OpenAI Whisper for voice commands"}),"\n",(0,s.jsx)(e.li,{children:"Natural language processing for command interpretation"}),"\n",(0,s.jsx)(e.li,{children:"Handling ambiguous or unclear commands"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Multi-modal interaction: speech, gesture, vision"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Combining multiple input modalities"}),"\n",(0,s.jsx)(e.li,{children:"Cross-modal attention and understanding"}),"\n",(0,s.jsx)(e.li,{children:"Coherent multi-modal responses"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"key-concepts",children:"Key Concepts"}),"\n",(0,s.jsx)(e.h3,{id:"conversational-ai-integration",children:"Conversational AI Integration"}),"\n",(0,s.jsx)(e.p,{children:"Integrating large language models with robots involves several challenges:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Command grounding"}),": Connecting language to physical actions"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"World modeling"}),": Maintaining a representation of the environment"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Action planning"}),": Translating high-level commands to low-level actions"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Feedback integration"}),": Using robot sensors to inform the conversation"]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"voice-to-action-pipeline",children:"Voice-to-Action Pipeline"}),"\n",(0,s.jsx)(e.p,{children:"The complete pipeline from voice command to robot action:"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Speech recognition"}),": Converting speech to text (Whisper)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Natural language understanding"}),": Interpreting the command"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Task decomposition"}),": Breaking complex commands into subtasks"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Action selection"}),": Choosing appropriate robot actions"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Execution"}),": Performing the actions using ROS 2"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Feedback"}),": Reporting results back to the user"]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"multi-modal-integration",children:"Multi-Modal Integration"}),"\n",(0,s.jsx)(e.p,{children:"Conversational robots can process multiple input types:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Visual input"}),": Cameras for scene understanding"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Audio input"}),": Microphones for speech and sound"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Tactile input"}),": Force/torque sensors for manipulation feedback"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Context"}),": Robot state, location, and history"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"capstone-project-the-autonomous-humanoid",children:"Capstone Project: The Autonomous Humanoid"}),"\n",(0,s.jsx)(e.p,{children:"The final project integrates all course concepts:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Voice Command Reception"}),': Using Whisper to receive a command like "Clean the room"']}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Cognitive Planning"}),": Using LLMs to translate the command into a sequence of actions"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Path Planning"}),": Using Nav2 to navigate obstacles"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Object Recognition"}),": Using computer vision to identify objects"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Manipulation"}),": Using robot arms to move objects"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Human Interaction"}),": Providing feedback and handling clarifications"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"practical-exercises",children:"Practical Exercises"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsx)(e.li,{children:"Integrate Whisper with ROS 2 for voice commands"}),"\n",(0,s.jsx)(e.li,{children:"Connect GPT models to robot control systems"}),"\n",(0,s.jsx)(e.li,{children:"Implement natural language to action mapping"}),"\n",(0,s.jsx)(e.li,{children:"Create a multi-modal interaction system"}),"\n",(0,s.jsx)(e.li,{children:"Complete the capstone project demonstration"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"assignments",children:"Assignments"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsx)(e.li,{children:"Capstone: Simulated humanoid robot with conversational AI"}),"\n",(0,s.jsx)(e.li,{children:"Demonstrate voice-to-action capabilities"}),"\n",(0,s.jsx)(e.li,{children:'Complete the "Clean the room" challenge'}),"\n"]})]})}function h(n={}){const{wrapper:e}={...(0,t.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(d,{...n})}):d(n)}}}]);